{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes Summary by team\n",
    "- No changes made to code\n",
    "- Only changes are newlines / spacings / cell locations / comments etc. \n",
    "- Some errors found and variables calculated that are not used, but nothing that affects results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GAP_TIME          = 6  # In hours\n",
    "WINDOW_SIZE       = 24 # In hours\n",
    "SEED              = 10\n",
    "ID_COLS           = ['subject_id', 'hadm_id', 'icustay_id']\n",
    "GPU               = '2'\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = GPU\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIMIC_EXTRACT_DATA = \"data/all_hourly_data.h5\"\n",
    "\n",
    "data_full_lvl2 = pd.read_hdf(MIMIC_EXTRACT_DATA, \"vitals_labs\")\n",
    "data_full_raw  = pd.read_hdf(MIMIC_EXTRACT_DATA, \"vitals_labs\")\n",
    "statics        = pd.read_hdf(MIMIC_EXTRACT_DATA, 'patients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Method takes in a df and imputes the missing data for the 'mean' columns.\n",
    "Also adds a columns specifying the time since the last recording\n",
    "\"\"\"\n",
    "\n",
    "def simple_imputer(df):\n",
    "    \n",
    "    # Create an object (idx) to more easily perform multi-index slicing.\n",
    "    idx = pd.IndexSlice\n",
    "    df = df.copy()\n",
    "\n",
    "    # Removes unwanted column name levels \n",
    "    if len(df.columns.names) > 2: \n",
    "        df.columns = df.columns.droplevel(('label', 'LEVEL1', 'LEVEL2'))\n",
    "\n",
    "    # Only keep those columns with mean and count values\n",
    "    df_out = df.loc[:, idx[:, ['mean', 'count']]]\n",
    "\n",
    "    # Group the data by subject, admission and icustay id and find the mean of the mean columns\n",
    "    icustay_means = df_out.loc[:, idx[:, 'mean']].groupby(ID_COLS).mean()\n",
    "\n",
    "    # Overwrites the values in the mean columns \n",
    "    df_out.loc[:,idx[:,'mean']] = df_out.loc[:,idx[:,'mean']].groupby(ID_COLS).fillna(\n",
    "        method='ffill'\n",
    "    ).groupby(ID_COLS).fillna(icustay_means).fillna(0)\n",
    "\n",
    "    # Sets the count columns as 1.0 if value > 0, o.p otherwise and sets as type float \n",
    "    # - Renames the column name to mask as no longer a count\n",
    "    df_out.loc[:, idx[:, 'count']] = (df.loc[:, idx[:, 'count']] > 0).astype(float)\n",
    "    df_out.rename(columns={'count': 'mask'}, level='Aggregation Function', inplace=True)\n",
    "\n",
    "    # Determines how long between measurements, based on the available 'mask'\n",
    "    is_absent = (1 - df_out.loc[:, idx[:, 'mask']])\n",
    "    hours_of_absence = is_absent.cumsum()\n",
    "    time_since_measured = hours_of_absence - hours_of_absence[is_absent==0].fillna(method='ffill')\n",
    "    time_since_measured.rename(columns={'mask': 'time_since_measured'}, level='Aggregation Function', inplace=True)\n",
    "\n",
    "    # Adds the 'time_since_measured' information to the df\n",
    "    # - Sets any missing 'time_since_measured' data to 100\n",
    "    df_out = pd.concat((df_out, time_since_measured), axis=1)\n",
    "    df_out.loc[:, idx[:, 'time_since_measured']] = df_out.loc[:, idx[:, 'time_since_measured']].fillna(100)\n",
    "\n",
    "    df_out.sort_index(axis=1, inplace=True)\n",
    "    \n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mort_hosp</th>\n",
       "      <th>mort_icu</th>\n",
       "      <th>los_3</th>\n",
       "      <th>los_7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>145834</th>\n",
       "      <th>211552</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>185777</th>\n",
       "      <th>294638</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>107064</th>\n",
       "      <th>228232</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>150750</th>\n",
       "      <th>220597</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>194540</th>\n",
       "      <th>229441</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99973</th>\n",
       "      <th>150202</th>\n",
       "      <th>275083</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99982</th>\n",
       "      <th>151454</th>\n",
       "      <th>221194</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99991</th>\n",
       "      <th>151118</th>\n",
       "      <th>226241</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99992</th>\n",
       "      <th>197084</th>\n",
       "      <th>242052</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <th>137810</th>\n",
       "      <th>229633</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23944 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               mort_hosp  mort_icu  los_3  los_7\n",
       "subject_id hadm_id icustay_id                                   \n",
       "3          145834  211552            0.0       0.0    1.0    0.0\n",
       "4          185777  294638            0.0       0.0    0.0    0.0\n",
       "6          107064  228232            0.0       0.0    1.0    0.0\n",
       "9          150750  220597            1.0       1.0    1.0    0.0\n",
       "11         194540  229441            0.0       0.0    0.0    0.0\n",
       "...                                  ...       ...    ...    ...\n",
       "99973      150202  275083            0.0       0.0    0.0    0.0\n",
       "99982      151454  221194            0.0       0.0    1.0    1.0\n",
       "99991      151118  226241            0.0       0.0    1.0    0.0\n",
       "99992      197084  242052            0.0       0.0    0.0    0.0\n",
       "99995      137810  229633            0.0       0.0    0.0    0.0\n",
       "\n",
       "[23944 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracts and calculated the data for the 4 desired outputs ('mort_hosp', 'mort_icu', 'los_3', 'los_7')\n",
    "# - Only select rows where there is at least 'WINDOW_SIZE + GAP_TIME' hours worth of data\n",
    "# - Create two new columns for ICU stay longer than 3 and 7 hours and remove original\n",
    "Ys = statics[statics.max_hours > WINDOW_SIZE + GAP_TIME][['mort_hosp', 'mort_icu', 'los_icu']]\n",
    "Ys['los_3'] = Ys['los_icu'] > 3\n",
    "Ys['los_7'] = Ys['los_icu'] > 7\n",
    "Ys.drop(columns=['los_icu'], inplace=True)\n",
    "Ys.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "# - Only keeps data which has same 'icustay_id' as the 'Ys' calculated above\n",
    "# - Only keeps data from the first 24 hours (WINDOW_SIZE)\n",
    "lvl2, raw = [df[\n",
    "    (df.index.get_level_values('icustay_id').isin(set(Ys.index.get_level_values('icustay_id')))) &\n",
    "    (df.index.get_level_values('hours_in') < WINDOW_SIZE)\n",
    "] for df in (data_full_lvl2, data_full_raw)]\n",
    "\n",
    "# Drops the level 2 column headings from raw\n",
    "raw.columns = raw.columns.droplevel(level=['LEVEL2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the 'subject_id' from the two data df and the output df\n",
    "# - Tests to ensure that they are all the same\n",
    "lvl2_subj_idx, raw_subj_idx, Ys_subj_idx = [df.index.get_level_values('subject_id') for df in (lvl2, raw, Ys)]\n",
    "lvl2_subjects = set(lvl2_subj_idx)\n",
    "assert lvl2_subjects == set(Ys_subj_idx), \"Subject ID pools differ!\"\n",
    "assert lvl2_subjects == set(raw_subj_idx), \"Subject ID pools differ!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the breakdown of train vs development vs test sizes\n",
    "train_frac, dev_frac, test_frac = 0.7, 0.1, 0.2\n",
    "\n",
    "# Uses the sizes to select the subjects for the three sets (train, dev, test) \n",
    "np.random.seed(SEED)\n",
    "subjects, N = np.random.permutation(list(lvl2_subjects)), len(lvl2_subjects)\n",
    "N_train, N_dev, N_test = int(train_frac * N), int(dev_frac * N), int(test_frac * N)\n",
    "train_subj = subjects[:N_train]\n",
    "dev_subj   = subjects[N_train:N_train + N_dev]\n",
    "test_subj  = subjects[N_train+N_dev:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uses the selected subject ID breakdown to extract the data for train, dev and test\n",
    "# from the data frames\n",
    "[(lvl2_train, lvl2_dev, lvl2_test), (raw_train, raw_dev, raw_test), (Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (lvl2, raw, Ys)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalises the 'mean' columns of the data\n",
    "# - Create an object (idx) to more easily perform multi-index slicing.\n",
    "# - Calculates the mean and std of each column which has \"mean\" in the column heading\n",
    "# - uses these values to normalise the same columns\n",
    "idx = pd.IndexSlice\n",
    "lvl2_means = lvl2_train.loc[:, idx[:,'mean']].mean(axis=0)\n",
    "lvl2_stds  = lvl2_train.loc[:, idx[:,'mean']].std(axis=0)\n",
    "\n",
    "lvl2_train.loc[:, idx[:,'mean']] = (lvl2_train.loc[:, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_dev.loc[  :, idx[:,'mean']] = (lvl2_dev.loc[  :, idx[:,'mean']] - lvl2_means)/lvl2_stds\n",
    "lvl2_test.loc[ :, idx[:,'mean']] = (lvl2_test.loc[ :, idx[:,'mean']] - lvl2_means)/lvl2_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Method takes in a df and imputes the missing data for the 'mean' columns.\n",
    "# - Also adds a columns specifying the time since the last recording\n",
    "# - NOTE: This time since last recording is not correct - but not used again later so has no bearing\n",
    "lvl2_train, lvl2_dev, lvl2_test = [\n",
    "    simple_imputer(df) for df in (lvl2_train, lvl2_dev, lvl2_test)\n",
    "]\n",
    "\n",
    "# Pivots the table so that there is one row per 'subject_id', 'hadm_id', 'icustay_id'\n",
    "# - Therefore in each row there are now:\n",
    "#    - 24 columns of mask (1 for each hour)\n",
    "#    - 24 columns of mean value\n",
    "#    - 24 columns of time_since_measured\n",
    "lvl2_flat_train, lvl2_flat_dev, lvl2_flat_test = [\n",
    "    df.pivot_table(index=['subject_id', 'hadm_id', 'icustay_id'], columns=['hours_in']) for df in (\n",
    "       lvl2_train, lvl2_dev, lvl2_test\n",
    "    )\n",
    "]\n",
    "\n",
    "# Runs a test to ensure no missing values remain\n",
    "for df in lvl2_train, lvl2_dev, lvl2_test: assert not df.isnull().any().any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the output df for train, dev and test\n",
    "# - NOTE: This has actually already been done in cell above, but going to leave it in as does no harm\n",
    "[(Ys_train, Ys_dev, Ys_test)] = [\n",
    "    [df[df.index.get_level_values('subject_id').isin(s)] for s in (train_subj, dev_subj, test_subj)] \\\n",
    "    for df in (Ys,)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all required data\n",
    "pd.to_pickle(lvl2_train, \"data/lvl2_imputer_train.pkl\")\n",
    "pd.to_pickle(lvl2_dev,   \"data/lvl2_imputer_dev.pkl\")\n",
    "pd.to_pickle(lvl2_test,  \"data/lvl2_imputer_test.pkl\")\n",
    "\n",
    "pd.to_pickle(Ys,       \"data/Ys.pkl\")\n",
    "pd.to_pickle(Ys_train, \"data/Ys_train.pkl\")\n",
    "pd.to_pickle(Ys_dev,   \"data/Ys_dev.pkl\")\n",
    "pd.to_pickle(Ys_test,  \"data/Ys_test.pkl\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,auto:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
